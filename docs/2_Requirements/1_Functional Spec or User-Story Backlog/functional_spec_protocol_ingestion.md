# Functional Specification â€“ Protocolâ€¯Ingestionâ€¯&â€¯Informationâ€¯Extraction

> **ContextÂ &Â Goals**  
> The Protocolâ€¯Ingestionâ€¯&â€¯Informationâ€¯Extraction (PIIE) feature automates the conversion of heterogeneous studyâ€‘protocol documents (DOCX, PDF, XML) into a validated **Studyâ€¯RequirementsÂ JSON** that downstream components (mapping, CRF generation, validation) consume.  
> Success is measured by (a) â‰¥90â€¯% extraction recall for targeted sections (Scheduleâ€¯ofâ€¯Assessments, Eligibilityâ€¯Criteria, etc.), (b) <5â€¯% manual curation rate after firstâ€‘pass NLP, and (c) completion within 2â€¯min for a 100â€‘page protocol.

---

## ğŸ“‘Â Table of Contents

1. [Glossary](#glossary)
2. [UserÂ StoriesÂ (byÂ Epic)](#user-stories)  
Â Â Â &nbsp;&nbsp;2.1Â [DocumentÂ Ingestion](#epic-ingest)  
Â Â Â &nbsp;&nbsp;2.2Â [TableÂ &Â SectionÂ Detection](#epic-structure)  
Â Â Â &nbsp;&nbsp;2.3Â [NLPâ€¯EntityÂ Extraction](#epic-nlp)  
Â Â Â &nbsp;&nbsp;2.4Â [CanonicalÂ IRÂ Persistence](#epic-ir)  
Â Â Â &nbsp;&nbsp;2.5Â [OperationalÂ LoggingÂ &Â ErrorÂ Handling](#epic-ops)
3. [Nonâ€‘Functionalâ€¯Notes](#nfr)
4. [OpenÂ QuestionsÂ &Â Dependencies](#open-questions)

---

## Glossary<a name="glossary"></a>

| Term | Definition |
|------|------------|
| **Importer** | Formatâ€‘specific module that reads a protocol (DOCX, PDF, XML) and emits raw text + tables. |
| **SectionÂ Header** | Humanâ€‘readable heading in protocol (e.g., *ScheduleÂ ofâ€¯Assessments*). |
| **CanonicalÂ IR** | JSON schema (StudyProtocolIR) capturing structured dataâ€‘collection requirements with provenance. |
| **Visit** | Planned timeâ€‘point in the trial where assessments occur (e.g., *ScreeningÂ Dayâ€¯â€“28Â toÂ â€“1*). |
| **Assessment** | Procedure or question to be captured on CRF (e.g., *12â€‘leadâ€¯ECG*). |
| **Provenance** | Link (page/line/table) from extracted requirement back to source document for auditability. |
| **ExtractionÂ Recall** | % of target requirements correctly identified by NLP pipeline. |

---

## UserÂ Stories<a name="user-stories"></a>

### EpicÂ PIâ€‘01Â â€“Â DocumentÂ Ingestion<a name="epic-ingest"></a>

| ID | UserÂ Story | AcceptanceÂ Criteria |
|----|-----------|---------------------|
| PIâ€‘01â€‘01 | As a **DataÂ Manager** I want to upload a *DOCX* protocol so that the system begins extraction automatically. | **Given** a valid DOCX fileâ€¯â‰¤â€¯50â€¯MB  
**When** I POST it to */ingest* via API  
**Then** a job is queuedÂ and returnsÂ 202 with jobâ€‘ID. |
| PIâ€‘01â€‘02 | As a **StudyÂ Designer** I want to see an error if the file type is unsupported so that I can fix the input early. | **Given** I upload a *.pptx* file  
**When** validation runs  
**Then** the service respondsÂ 400 *â€œUnsupported formatâ€*. |

### EpicÂ PIâ€‘02Â â€“Â TableÂ &Â SectionÂ Detection<a name="epic-structure"></a>

| ID | UserÂ Story | AcceptanceÂ Criteria |
|----|-----------|---------------------|
| PIâ€‘02â€‘01 | As an **NLPÂ Engineer** I want section headers classified so that downstream extractors focus only on relevant portions. | **Given** a parsed protocol  
**When** section detection executes  
**Then** each sentence is tagged with its parent section (*e.g.,Â SOA, InclusionÂ Criteria*). |
| PIâ€‘02â€‘02 | As a **Developer** I want tables extracted asÂ CSV so that row/column semantics are preserved. | **Given** a DOCX table with merged headers  
**When** import completes  
**Then** the table is emitted as normalized CSVÂ with header hierarchy flattened. |

### EpicÂ PIâ€‘03Â â€“Â NLPâ€¯Entityâ€¯Extraction<a name="epic-nlp"></a>

| ID | UserÂ Story | AcceptanceÂ Criteria |
|----|-----------|---------------------|
| PIâ€‘03â€‘01 | As a **DataÂ Scientist** I want visits, assessments, and timing entities recognised so that they map to CDASH later. | **Given** a sentence â€œVital signs will be recorded at Screening and WeekÂ 4â€  
**When** NLP runs  
**Then** entities *(VitalÂ Signs)*â€‘Assessment, *(Screening,Â WeekÂ 4)*â€‘Visit are returned with confidenceÂ â‰¥0.8. |
| PIâ€‘03â€‘02 | As a **RegulatoryÂ Lead** I want provenance captured for every extracted entity so that audit requirements are met. | **Given** a table cell in SOA  
**When** the assessment is extracted  
**Then** provenance includes pageÂ num, tableÂ ID, row/col indices. |

### EpicÂ PIâ€‘04Â â€“Â CanonicalÂ IRÂ Persistence<a name="epic-ir"></a>

| ID | UserÂ Story | AcceptanceÂ Criteria |
|----|-----------|---------------------|
| PIâ€‘04â€‘01 | As a **BackendÂ Developer** I want validated JSON persisted so that later stages consume consistent schemas. | **Given** extracted entities  
**When** Pydantic validation passes  
**Then** StudyProtocolIR JSON is stored with SHAâ€‘256 hash and statusÂ *ready*. |
| PIâ€‘04â€‘02 | As a **CROÂ TechÂ Lead** I want a hash manifest generated so that we can support 21Â CFRÂ PartÂ 11 eâ€‘signatures. | **Given** the IR JSON file  
**When** ingestion completes  
**Then** a manifest file lists filename + SHAâ€‘256 hash + timestamp. |

### EpicÂ PIâ€‘05Â â€“Â OperationalÂ LoggingÂ &Â ErrorÂ Handling<a name="epic-ops"></a>

| ID | UserÂ Story | AcceptanceÂ Criteria |
|----|-----------|---------------------|
| PIâ€‘05â€‘01 | As a **SiteÂ Reliabilityâ€¯Engineer** I want structured logs for each ingestion step so that incidents can be triaged quickly. | **Given** ingestion of protocolÂ XYZ  
**When** any subâ€‘step fails  
**Then** a JSON log entry with level=ERROR, stepÂ name, traceÂ ID is written to AuditLog table. |
| PIâ€‘05â€‘02 | As a **SupportÂ Analyst** I want extraction quality metrics emitted so that we can monitor model drift. | **Given** completion of NLP extraction  
**When** metrics computed  
**Then** the job summary includes counts for entities found, confidence distribution, and extraction recall estimate. |

---

## Nonâ€‘FunctionalÂ Notes<a name="nfr"></a>

* **Performance:** Process â‰¤100â€‘page DOCX in <2â€¯min (P90).  
* **Scalability:** Async pipeline must allow â‰¥10 concurrent ingestions (*see NFRâ€‘PERFâ€‘02*).  
* **Compliance:** Audit trail + hash manifest per 21â€¯CFRâ€¯11 (*see NFRâ€‘COMPâ€‘01*).  
* **Security:** Only authenticated roles may call */ingest*; files encryptedÂ atÂ rest (NFRâ€‘SECâ€‘03).  
* **Standards:** Canonical IR schema versioned; backward compatibility guaranteed for MINOR releases.

---

## OpenÂ QuestionsÂ &Â Dependencies<a name="open-questions"></a>

1. **PDF Table Accuracy** â€“ Do we set minimum recall thresholds or flag PDF imports as *bestâ€‘effort* only?
2. **Statistical vs Ruleâ€‘based NER** â€“ MVP uses rules; what criteria trigger upgrade to ML model?
3. **Storage Layer** â€“ IR JSON persisted in Postgres JSONB vs object storage? Decision affects queryâ€‘ability.
4. **Concurrency Limits** â€“ Alignment with DevOps capacity planning; limits to be defined in Ops playbook.
5. **Internationalization** â€“ Initial protocols assumed English; timeline for multilingual support?

---
*[Return to Top](#functional-spec-protocol-ingestion)
